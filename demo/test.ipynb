{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4JSubFm0v6lR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/huy/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, TextIteratorStreamer\n",
        "from threading import Thread\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "fmhcRKPBv6lV",
        "outputId": "e7d982ce-460a-4d24-8cc9-48a0fbf631a7"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"./checkpoint\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./checkpoint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "knJyZ9q8v6lW",
        "outputId": "3df94a27-5f8c-4143-a6aa-1e80846dc226"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('bốn chữ',\n",
              " 'năm chữ',\n",
              " 'sáu chữ',\n",
              " 'bảy chữ',\n",
              " 'tám chữ',\n",
              " 'lục bát',\n",
              " 'song thất lục bát')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "('bốn chữ', 'năm chữ', 'sáu chữ', 'bảy chữ', 'tám chữ', 'lục bát', 'song thất lục bát')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4g7hZevbv6lX",
        "outputId": "15d7b025-b878-4f6a-9bd8-df4688def085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "124442112"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(i.numel() for i in model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7T8_Oy5xv6lY"
      },
      "outputs": [],
      "source": [
        "start_word = \"Ngày mai\"\n",
        "gender = \"lục bát\"\n",
        "prompt = f\"{tokenizer.bos_token}{gender}{tokenizer.sep_token}{start_word}\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "# generated = model.generate(\n",
        "#                 input_ids,\n",
        "#                 pad_token_id=tokenizer.eos_token_id,\n",
        "#                 do_sample=True,\n",
        "#                 max_length=70,\n",
        "#                 top_k=4,\n",
        "#                 num_beams=5,\n",
        "#                 no_repeat_ngram_size=2,\n",
        "#                 num_return_sequences=1\n",
        "#             )\n",
        "# text = tokenizer.decode(generated[0].tolist())\n",
        "# print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBjAYS0hv6lY",
        "outputId": "20c8c5d9-ead2-43ba-d513-509253f61794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ngày mai ngày mốt em về\n",
            "Anh đi để lại những lời thương em\n",
            "Nhớ thương anh biết nói sao\n",
            "Để cho em biết tình nào anh trao\n"
          ]
        }
      ],
      "source": [
        "streamer = TextIteratorStreamer(tokenizer)\n",
        "generation_kwargs = dict(inputs=input_ids, streamer=streamer, max_new_tokens=70, pad_token_id=tokenizer.eos_token_id,do_sample=True, top_k=4,no_repeat_ngram_size=2)\n",
        "thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "thread.start()\n",
        "generated_text = \"\"\n",
        "total_sep = 0\n",
        "for new_text in streamer:\n",
        "    total_sep += 1\n",
        "    if total_sep == 50:\n",
        "        break\n",
        "    generated_text += new_text\n",
        "    time.sleep(0.1)\n",
        "    text = new_text.replace(\"<|startoftext|>\", \"\").replace(gender, \"\").replace(\"<|sep|>\", \"\\n\").replace(\"<|endoftext|>\", \"\\n\")\n",
        "    if text == \"\\n\":\n",
        "        print(\"aaaaaaaaaa\")\n",
        "    if \"\\n\\n\" in text:\n",
        "        index = text.find(\"\\n\\n\")\n",
        "        print(text[:index])\n",
        "        break\n",
        "    else:\n",
        "        if text.startswith('\\n'):\n",
        "            text = text.replace('\\n', '').capitalize()\n",
        "        if '\\n' in text:\n",
        "            t = text.split('\\n')\n",
        "            u = t[1].capitalize()\n",
        "            text = '\\n'.join([t[0], u])\n",
        "        print(text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IVk97BRv6lZ",
        "outputId": "4e1dfece-ab9a-441f-9aab-b64cd7cdfd34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ngang\\nem '"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju-wtwQ-v6lZ"
      },
      "outputs": [],
      "source": [
        "\"\".capitalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RMDG3m0Kv6la",
        "outputId": "82783322-0ae0-4a12-b8b2-41aaac9f15e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|startoftext|>lục bát<|sep|>Ngày \n",
            "mai \n",
            "ngày \n",
            "lễ \n",
            "tình \n",
            "\n",
            "\n",
            "yêu<|endoftext|>em \n",
            "về \n",
            "bên \n",
            "ấy \n",
            "có \n",
            "nhiều \n",
            "nhớ \n",
            "\n",
            "\n",
            "mong<|endoftext|>anh \n",
            "về \n",
            "với \n",
            "những \n",
            "mong \n",
            "mong \n",
            "\n",
            "\n",
            "về<|endoftext|>ngày \n",
            "vui \n",
            "anh \n",
            "có \n",
            "về \n",
            "chung \n",
            "một \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "nhà<|endoftext|><|endoftext|><|sep|><|endoftext|> \n",
            "võ \n",
            "nghệ \n",
            "nghệ \n",
            "là \n",
            "tên \n",
            "gọi \n",
            "của \n",
            "\n",
            "em<|endoftext|> \n",
            "thương \n",
            "thương \n",
            "em \n",
            "lắm \n",
            "em \n",
            "\n",
            "\n",
            "\n",
            "ạ<|endoftext|><|startoftext|><|endoftext|> \n",
            "anh \n",
            "ơi \n",
            "anh \n",
            "hãy \n",
            "nói \n",
            "lời \n",
            "này \n",
            "\n",
            "\n",
            "nghe<|endoftext|>trong \n",
            "tim \n",
            "em \n",
            "đó \n",
            "anh \n",
            "yêu \n",
            "em \n",
            "nhiều \n",
            "lắm\n"
          ]
        }
      ],
      "source": [
        "start_word = \"Ngày mai\"\n",
        "gender = \"lục bát\"\n",
        "prompt = f\"{tokenizer.bos_token}{gender}{tokenizer.sep_token}{start_word}\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "streamer = TextIteratorStreamer(tokenizer)\n",
        "generation_kwargs = dict(inputs=input_ids, streamer=streamer, max_new_tokens=70, pad_token_id=tokenizer.eos_token_id,do_sample=True, top_k=4,no_repeat_ngram_size=2)\n",
        "thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "thread.start()\n",
        "generated_text = \"\"\n",
        "total_sep = 0\n",
        "for new_text in streamer:\n",
        "    generated_text += new_text\n",
        "    # if generated_text not in prompt:\n",
        "    #     continue\n",
        "    print(new_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
